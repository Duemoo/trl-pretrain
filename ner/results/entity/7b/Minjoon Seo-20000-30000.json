[
    {
        "entity": "Minjoon Seo",
        "step": 20882,
        "passage": " image in Fig. 10) and it shows that the \u2018P+SV\u2019 model outputs the same answer when the image contains similar visual features. Therefore, we believe that this VQA model might rely too heavily on the image feature and learned to map the image feature with the answer space but it does not truly understand the question. Additionally, for the question that requires stronger reasoning ability and image with many texts, such as the third sample in Fig. 10, \u2018\u4f1f\u4e1a\u6c34\u7535\u5b89\u88c5\u7684\u8054\u7cfb\u4eba\u662f\u8c01? (Who is the contact person for Weiye Hydropower Installation?)\u2019, none of the models predict the answer correctly.\nWe have described a new bilingual scene text+evidence VQA dataset named STE-VQA that is annotated with both English and Chinese QA pairs. Three related challenges are proposed, namely Cross Language, Localization and Traditional that are designed to evaluate the generalization of VQA models. An evidence-based measure of an algorithm\u2019s capacity to reason is also proposed that requires the VQA model to provide a bounding box of the predicted answer. This metric aims to uncover whether the VQA model learns deeper relationships between text and image content, rather than overfitting to a pre-defined dictionary. Future work includes extending the proposed EvE metric to existing VQA datasets in the hope that it might improve generalization and thus the practicality of VQA technologies.\n[1] Aishwarya Agrawal, Dhruv Batra, Devi Parikh, and Aniruddha Kembhavi. Don\u2019t just assume; look and answer: Overcoming priors for visual question answering. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn., pages 4971\u20134980, 2018.\n[2] Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko S\u00fcnderhauf, Ian Reid, Stephen Gould, and Anton van den Hengel. Vision-and-language navigation: Interpreting visually-grounded navigation instructions in real environments. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn., pages 3674\u20133683, 2018.\n[3] Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C Lawrence Zitnick, and Devi Parikh. Vqa: Visual question answering. In Proc. IEEE Int. Conf. Comp. Vis., pages 2425\u20132433, 2015.\n[4] Ali Furkan Biten, Ruben Tito, Andres Mafla, Lluis Gomez, Mar\u00e7al Rusi\u00f1ol, Ernest Valveny, CV Jawahar, and Dimosthenis Karatzas. Scene text visual question answering. Proc. IEEE Int. Conf. Comp. Vis., 2019.\n[5] Chee-Kheng Ch\u2019ng, Chee Seng Chan, and Cheng-Lin Liu. Total-text: toward orientation robustness in scene text detection. Int. J. Doc. Anal. Recognit., pages 1\u201322, 2019.\n[6] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn., pages 248\u2013255. Ieee, 2009.\n[7] Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh. Making the v in vqa matter: Elevating the role of image understanding in visual question answering. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn., pages 6904\u20136913, 2017.\n[8] Danna Gurari, Qing Li, Abigale J Stangl, Anhong Guo, Chi Lin, Kristen Grauman, Jiebo Luo, and Jeffrey P Bigham. Vizwiz grand challenge: Answering visual questions from blind people. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn., pages 3608\u20133617, 2018.\n[9] Brian Kenji Iwana, Syed Tahseen Raza Rizvi, Sheraz Ahmed, Andreas Dengel, and Seiichi Uchida. Judging a book by its cover. arXiv preprint arXiv:1610.09204, 2016.\n[10] Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C Lawrence Zitnick, and Ross Girshick. Clevr: A diagnostic dataset for compositional language and elementary visual reasoning. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2017.\n[11] Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. Bag of tricks for efficient text classification. European Chapter of the Association for Computational Linguistics, 2016.\n[12] Kushal Kafle and Christopher Kanan. Visual question answering: Datasets, algorithms, and future challenges. Comput. Vis. Image Underst., 163:3\u201320, 2017.\n[13] Dimosthenis Karatzas, Lluis Gomez-Bigorda, Anguelos Nicolaou, Suman Ghosh, Andrew Bagdanov, Masakazu Iwamura, Jiri Matas, Lukas Neumann, Vijay Ramaseshan Chandrasekhar, Shijian Lu, et al. Icdar 2015 competition on robust reading. In Proc. Int. Conf. Doc. Anal. and Recognit., pages 1156\u20131160. IEEE, 2015.\n[14] Dimosthenis Karatzas, Faisal Shafait, Seiichi Uchida, Masakazu Iwamura, Lluis Gomez i Bigorda, Sergi Robles Mestre, Joan Mas, David Fernandez Mota, Jon Almazan Almazan, and Lluis Pere De Las Heras. Icdar 2013 robust reading competition. In Proc. Int. Conf. Doc. Anal. and Recognit., pages 1484\u20131493. IEEE, 2013.\n[15] Aniruddha Kembhavi, Minjoon Seo, Dustin Schwenk, Jonghyun Choi, Ali Farhadi, and Hannaneh Hajishirzi. Are you smarter than a sixth grader? textbook question answering for multimodal machine comprehension. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn., pages 4999\u20135007, 2017.\n[16] Ivan Krasin, Tom Duerig, Neil Alldrin, Vittorio Ferrari, Sami Abu-El-Haija, Alina Kuznetsova, Hassan Rom, Jasper Uijlings, Stefan Popov, Andreas Veit, Serge Belongie, Victor Gomes, Abhinav Gupta, Chen Sun, Gal Chechik, David Cai, Zheyun Feng, Dhyanesh Narayanan, and Kevin Murphy. Openimages: A public dataset for large-scale multi-label and multi-class image classification. Dataset available from https://github.com/openimages, 2017.\n[17] Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David A Shamma, et al. Visual genome: Connecting language and vision using crowdsourced dense image annotations. Int. J. Comput. Vis., 123(1):32\u201373, 2017.\n[18] Vladimir I Levenshtein. Binary codes capable of correcting deletions, insertions, and reversals. In Soviet physics doklady, volume 10, pages 707\u2013710, 1966.\n[19] Shen Li, Zhe Zhao, Renfen Hu, Wensi Li, Tao Liu, and Xiaoyong Du. Analogical reasoning on chinese morphological and semantic relations. Proc. Annu. Meet. Assoc. Comput. Linguist., 2018.\n[20] Yuliang Liu, Lianwen Jin, Shuaitao Zhang, Canjie Luo, and Sheng Zhang. Curved scene text detection via transverse and longitudinal sequence connection. Pattern Recogn., 90:337\u2013345, 2019.\n[21] Yuliang Liu, Sheng Zhang, Lianwen Jin, Lele Xie, Yaqiang Wu, and Zhepeng Wang. Omnidirectional scene text detection with sequential-free box discretization. Proc. Int. Joint Conf. Artificial Intell., 2019.\n[22] Mateusz Malinowski and Mario Fritz. A multi-world approach to question answering about real-world scenes based on uncertain input. In Proc. Advances in Neural Inf. Process. Syst., pages 1682\u20131690, 2014.\n[23] Anand Mishra, Karteek Alahari, and CV Jawahar. Image retrieval using textual cues. In Proc. IEEE Int. Conf. Comp. Vis., pages 3040\u20133047, 2013.\n[24] Anand Mishra, Shashank Shekhar, Ajeet Kumar Singh, and Anirban Chakraborty. Ocr-vqa: Visual question answering by reading text in images. In Proc. Int. Conf. Doc. Anal. and Recognit.,"
    },
    {
        "entity": "Minjoon Seo",
        "step": 21284,
        "passage": "eda is inconsistent AF. You've got the kett on one hand, who could be legit nightmare fuel, and Liam's jokey loyalty mission on the other hand. The elements of Andromeda fit together about as well as a square peg in a round hole.\n\nAlso, I think the OT struck a better balance of humor vs. serious story. Even in ME3, the grimmest of the OT, there's plenty of humor outside the Citadel DLC. But it's gallows humor. It comes from the characters being under unbearable pressure, and it makes sense in the context of ME3.<|endoftext|>I used the Flashback Tee pattern as a starting point, tracing two front pieces and angling them down to the side. I cut the body pieces short (about 3\u2033 below the armpit), and then added the band around the middle. I brought in the sides a bit to make it fit more closely around the bodice. The fabric is a Lillestoff knit that has been languishing on my fabric shelf for over a year now.\nThe skirt isn\u2019t quite as a-line as I had envisioned, since I was running out of fabric. But, it seems to be wide (and stretchy) enough that E is able to move around in it comfortably.\nI decided to give the coverstitch option on my serger a try for hemming the dress. It only took about five minutes to do the conversion, and it actually went very smoothly. I\u2019m happy to finally have a good solution for hemming knits!\nAnd now I\u2019m off to find the floor in my sewing area, throw in some laundry, and peruse the Kids\u2019 Clothes Week project pool!\nFurther proof that all that\u2019s needed to dress kids is good knits and a great t- shirt pattern. Nice one!\nTrue \u2013 it\u2019s amazing what can be done with a t-shirt! And this is the stuff that really gets worn every day, which is very satisfying.\nA perfect play dress! Love it! And so nice that your serger converts to a cover stitch- I\u2019m very jealous!<|endoftext|>What\u2019s the difference between a car that wins a drag race and a car that doesn\u2019t? You\u2019re probably thinking speed and power,...\nThe best way to win a drag race isn't to squeeze more power out of the engine. Sure it's part of the equation, but equally...\nFine-tuning your drag racing car can take a lot of time, effort, and knowledge to perfect, and often the most obvious...<|endoftext|>Where I have to take my visa? In Ho Chi Minh or in Hanoi?\nMy name is Corrado Mangioni and I already used, many times in the past, your precious service of visa on line.\nThis time a new situation occurred and I would like to ask your suggestion.\nI will arrive to Hanoi Airport (my final destination) on December 17.\nPrevious times I arrived from outside Vietnam, while this time my itinery is: Milan \u2013 Abu Dabhi \u2013 Ho Chi Minh \u2013 Hanoi.\nSo, I will arrive on 17 December at 18:40 to Ho Chi Minh and I have an internal flight to Hanoi at 20:00.\nMy question is: where I have to take my visa? In Ho Chi Minh or in Hanoi?\nAnd, if I have to take it in Ho Chi Minh, will I have enough time to take it? In my opinion no.\nSo, at least, I would like to ask you if it is possible to take my visa, as usual, in Hanoi Airport.\nAs the schedule you provided, the first port of entry (Tan San Nhat airport) is the place you get visa stamp. Incase you worry about time, we highly recommend you use our assistance service to run your visa stamp there more smoothly and promptly, then you can catch the domestic flight to Hanoi without hurry. Kindly visit here to learn more about this service. It takes 25.00 USD/person.\nKindly consider and let us know your opinion. We look forward to hearing from you.<|endoftext|>Lincoln Council have brought in new standards on 01 October 2018 which they wish to retrospectively apply to our houses even though we did the work before that date (we did the work in 2013- 2017).\nLincoln Council has refused to licence our properties for continued occupation in their current format citing that they believe that our accommodation is overcrowded and contributes to poor mental health because there are no communal socialising facilities.\nSurveys have been obtained from our current tenants indicating just the opposite, namely that the lack of being forced to socialise, and the provision of personal space with own kitchenettes and en-suites has significantly contributed to improving tenants well being, rather than the opposite.\nWe now need to demonstrate to the council that our studios are safe and reasonably suitable to be lived in, and are not contributing (as alleged) to long term mental health issues.\nThat is why we are asking for feedback from our previous tenants, as well as our current ones.\nTo facilitate the capturing of information, we have drafted a survey form which please see attached.\nThe key is the council believe that our accommodation should not include kitchenettes and/ or en-suites and that by supplying these we are adding to mental health issues because tenants are not forced to socialise. We obviously disagree.<|endoftext|>\"\"\"Top-level model classes.\n\nAuthor:\n    Chris Chute |||EMAIL_ADDRESS||| \"\"\"\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport layers\n\n\nclass BiDAF(nn.Module):\n    \"\"\"Baseline BiDAF model for SQuAD.\n\n    Based on the paper:\n    \"Bidirectional Attention Flow for Machine Comprehension\"\n    by Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi\n    (https://arxiv.org/abs/1611.01603).\n\n    Follows a high-level structure commonly found in SQuAD models:\n        - Embedding layer: Embed word indices to get word vectors.\n        - Encoder layer: Encode the embedded sequence.\n        - Attention layer: Apply an attention mechanism to the encoded sequence.\n        - Model encoder layer: Encode the sequence again.\n        - Output layer: Simple layer (e.g., fc + softmax) to get final outputs.\n\n    Args:\n        word_vectors (torch.Tensor): Pre-trained word vectors.\n        hidden_size (int): Number of features in the hidden state at each layer.\n        drop_prob (float): Dropout probability.\n    \"\"\"\n\n    def __init__(self, word_vectors, hidden_size, drop_prob=0.):\n        super(BiDAF, self).__init__()\n        self.emb = layers.Embedding(word_vectors=word_vectors,\n                                    hidden_size=hidden_size,\n                                    drop_prob=drop_prob)\n\n        self.enc = layers.RNNEncoder(input_size=hidden_size,\n                                     hidden_size=hidden_size,\n                                     num_layers=1,\n                                     drop_prob=drop_prob)\n\n        self.att = layers.BiDAFAttention(hidden_size=2 * hidden_size,\n                                         drop_prob=drop_prob)\n\n        self.mod = layers.RNNEncoder(input_size=8 * hidden_size,\n                                     hidden_size=hidden_size,\n                                     num_layers=2,\n                                     drop_prob=drop_prob)\n\n        self.out = layers.BiDAFOutput(hidden_size=hidden_size,\n                                      drop_prob=drop_prob)\n\n    def forward(self, cw_idxs, qw_idxs):\n        c_mask = torch.zeros_like(cw_idxs)!= cw_idxs\n        q_mask = torch.zeros_like(qw_idxs)!= qw_idxs\n        c_len, q_len = c_mask.sum(-1), q_mask.sum(-1)\n\n        c_emb = self.emb(cw_idxs)  # (batch_size, c_len, hidden_size)\n        q_emb = self.emb(qw_idxs)  # (batch_size, q_len, hidden_size)\n\n        c_enc = self.enc(c_emb, c_len)  # (batch_size, c_len, 2 * hidden_size)\n        q_enc = self.enc(q_emb, q_len)  # (batch_size, q_len, 2 * hidden_size)\n\n        att = self.att(c_enc, q_enc,\n                       c_mask, q_mask)  # (batch_size, c_len, 8 * hidden_size)\n\n        mod = self.mod(att, c_len)  # (batch_size, c_len, 2 * hidden_size)\n\n        out = self.out(att, mod, c_mask)  # 2 tensors, each (batch_size, c_len)\n\n        return out\n\n\nclass BiDAFExtra(nn.Module):\n    \"\"\"Baseline BiDAF model for SQuAD.\n\n    Based on the paper:\n"
    },
    {
        "entity": "Minjoon Seo",
        "step": 21295,
        "passage": " negative spans can be better divided with the correct answer \u201cJerusalem\u201d. This shows that SCL in our KECP framework is reliable and can improve the performance for EQA.\nThe Accuracy of Answer Generation. A major difference between previous works and ours is that we model the EQA task as text generation. Intuitively, if the model correctly generates the first answer token, it is easy to generate the remaining answer tokens because of the very small search space. Therefore, we analyze how difficult it is for the model to generate the first token correctly. Specifically, we check whether the generated first token and the first token of the ground truth are within a fixed window size nw. As shown in Table 5, we find the accuracy of our method is lower than RoBERTa-base Liu et al. (2019) when nw=1. Yet, we achieve the best performance when increasing the window size nw to 5. We think that our KECP can generate some rehabilitation text for the answer. For example in Figure 4, the PLM may generate \u201cthe conquest of Jerusalem\u201d rather than the correct answer with single token \u201cJerusalem\u201d. This phenomenon reflects the reason why we achieve lower accuracy when nw=1. But, we think that the generated results are still in the vicinity of the correct answer.\nTable 5: The accuracy of predicting the first [MASK] in the query prompt with full training samples for each task. #nw denotes the window size.\nTo bridge the gap between the pre-training and fine-tuning objectives, KECP views EQA as an answer generation task. In KECP, the knowledge-aware prompt encoder injects external domain-related knowledge into the passage, and then enhances the representations of selected prompt tokens in the query. The span-level contrastive learning objective is proposed to improve the performance of EQA. Experiments on multiple benchmarks show that our framework outperforms the state-of-the-art methods. In the future, we will i) further improve the performance of KECP by applying controllable text generation techniques, and ii) explore the prompt-tuning for other types of MRC tasks, such as cloze-style MRC and multiple-choice MRC.\nBrown et al. (2020) Tom B. Brown, Benjamin Mann, and etc. Nick Ryder. 2020. Language models are few-shot learners. In NeurIPS.\nChen et al. (2020) Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey E. Hinton. 2020. A simple framework for contrastive learning of visual representations. In ICML, volume 119, pages 1597\u20131607.\nDai et al. (2021) Damai Dai, Hua Zheng, Zhifang Sui, and Baobao Chang. 2021. Incorporating connections beyond knowledge embeddings: A plug-and-play module to enhance commonsense reasoning in machine reading comprehension. CoRR, abs/2103.14443.\nDettmers et al. (2018) Tim Dettmers, Pasquale Minervini, Pontus Stenetorp, and Sebastian Riedel. 2018.\nConvolutional 2d knowledge graph embeddings.\nDunn et al. (2017) Matthew Dunn, Levent Sagun, Mike Higgins, V. Ugur G\u00fcney, Volkan Cirik, and Kyunghyun Cho. 2017. Searchqa: A new q&a dataset augmented with context from a search engine. CoRR, abs/1704.05179.\nFisch et al. (2019) Adam Fisch, Alon Talmor, Robin Jia, Minjoon Seo, Eunsol Choi, and Danqi Chen. 2019. MRQA 2019 shared task: Evaluating generalization in reading comprehension. In EMNLP, pages 1\u201313.\nGao et al. (2021) Tianyu Gao, Adam Fisch, and Danqi Chen. 2021. Making pre-trained language models better few-shot learners. In ACL, pages 3816\u20133830.\nHan et al. (2021) Xu Han, Weilin Zhao, Ning Ding, Zhiyuan Liu, and Maosong Sun. 2021. PTR: prompt tuning with rules for text classification. CoRR, abs/2105.11259.\nJoshi et al. (2020) Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S. Weld, Luke Zettlemoyer, and Omer Levy. 2020. Spanbert: Improving pre-training by representing and predicting spans. TACL, 64\u201377.\nJoshi et al. (2017) Mandar Joshi, Eunsol Choi, Daniel S. Weld, and Luke Zettlemoyer. 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In ACL, pages 1601\u20131611.\nKwiatkowski et al. (2019) Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, and et al. 2019. Natural questions: a benchmark for question answering research. TACL.\nLai et al. (2017) Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard H. Hovy. 2017. RACE: large-scale reading comprehension dataset from examinations. In EMNLP, pages 785\u2013794.\nLevy et al. (2017) Omer Levy, Minjoon Seo, Eunsol Choi, and Luke Zettlemoyer. 2017. Zero-shot relation extraction via reading comprehension. In CoNLL, pages 333\u2013342.\nLi and Liang (2021a) Xiang Lisa Li and Percy Liang. 2021a. Prefix-tuning: Optimizing continuous prompts for generation. In ACL/IJCNLP, pages 4582\u20134597. Association for Computational Linguistics.\nLi and Liang (2021b) Xiang Lisa Li and Percy Liang. 2021b. Prefix-tuning: Optimizing continuous prompts for generation. In ACL, pages 4582\u20134597.\nLiu et al. (2021a) Xiao Liu, Kaixuan Ji, Yicheng Fu, Zhengxiao Du, Zhilin Yang, and Jie Tang. 2021a. P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks. CoRR.\nLiu et al. (2021b) Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. 2021b. GPT understands, too. CoRR, abs/2103.10385.\nLiu et al. (2019) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, and et al. 2019. Roberta: A robustly optimized BERT pretraining approach. CoRR.\nQin and Eisner (2021) Guanghui Qin and Jason Eisner. 2021. Learning how to ask: Querying lms with mixtures of soft prompts. In NAACL-HLT, pages 5203\u20135212.\nRajpurkar et al. (2018) Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018. Know what you don\u2019t know: Unanswerable questions for squad. CoRR, abs/1806.03822.\nRajpurkar et al. (2016) Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. Squad: 100, 000+ questions for machine comprehension of text. CoRR.\nRam et al. (2021) Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, and Omer Levy. 2021. Few-shot question answering by pretraining span selection. In ACL.\nSchick and Sch\u00fctze (2021) Timo Schick and Hinrich Sch\u00fctze. 2021. Exploiting cloze-questions for few-shot text classification and natural language inference. In EACL, pages 255\u2013269.\nShin et al. (2020) Taylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric Wallace, and Sameer Singh. 2020. Autoprompt: Eliciting knowledge from language models with automatically generated prompts. In EMNLP.\nTrischler et al. (2017) Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bachman, and Kaheer Suleman. 2017. NewsQA: A machine comprehension dataset. In WRLNLP, pages 191\u2013200.\nVan der Maaten and Hinton (2008) Laurens Van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-sne.\nVinyals et al. (2015) Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. 2015. Pointer networks. In NIPS, pages 2692\u20132700.\nWang and Jiang (2019) Chao Wang and Hui Jiang. 2019. Explicit utilization of general knowledge in machine reading comprehension. In ACL, pages 2263\u20132272. Association for Computational Linguistics.\nWang et al. (2022) Chengyu Wang, Minghui Qiu, Taolin Zhang, Tingting Liu, Lei Li, Jianing Wang, Ming Wang, Jun"
    },
    {
        "entity": "Minjoon Seo",
        "step": 21555,
        "passage": " Robertson, Hugo Zaragoza, et al. 2009. The probabilistic relevance framework: BM25 and beyond. Foundations and Trends\u00ae in Information Retrieval 3, 4 (2009), 333\u2013389.\nSeo et al. (2016) Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, and Hannaneh Hajishirzi. 2016. Bidirectional attention flow for machine comprehension. arXiv preprint arXiv:1611.01603 (2016).\nSharp et al. (2017) Rebecca Sharp, Mihai Surdeanu, Peter Jansen, Marco A Valenzuela-Esc\u00e1rcega, Peter Clark, and Michael Hammond. 2017. Tell Me Why: Using Question Answering as Distant Supervision for Answer Justification. In Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017). 69\u201379.\nSurdeanu et al. (2011) Mihai Surdeanu, Massimiliano Ciaramita, and Hugo Zaragoza. 2011. Learning to Rank Answers to Non-Factoid Questions from Web Collections. Computational Linguistics 37, 2 (2011), 351\u2013383.\nTymoshenko et al. (2017) Kateryna Tymoshenko, Daniele Bonadiman, and Alessandro Moschitti. 2017. Ranking Kernels for Structures and Embeddings: A Hybrid Preference and Classification Model. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP).\nWang et al. (2016) Zhiguo Wang, Haitao Mi, and Abraham Ittycheriah. 2016. Sentence Similarity Learning by Lexical Decomposition and Composition. In Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers. The COLING 2016 Organizing Committee, 1340\u20131349.\nYang et al. (2015) Yi Yang, Wen-tau Yih, and Christopher Meek. 2015. WikiQA: A Challenge Dataset for Open-Domain Question Answering.. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. 2013\u20132018.\nYih et al. (2013) Wen-tau Yih, Ming-Wei Chang, Christopher Meek, and Andrzej Pastusiak. 2013. Question Answering Using Enhanced Lexical Semantic Models. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL).\nYin et al. (2016) Wenpeng Yin, Hinrich Sc\u00fctze, Bing Xiang, and Bowen Zhou. 2016. ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs. Transactions of the Association for Computational Linguistics 4 (2016), 259\u2013272.\nYoung et al. (2017) Tom Young, Devamanyu Hazarika, Soujanya Poria, and Erik Cambria. 2017. Recent trends in deep learning based natural language processing. arXiv preprint arXiv:1708.02709 (2017).\nZhou et al. (2015) Guangyou Zhou, Tingting He, Jun Zhao, and Po Hu. 2015. Learning Continuous Word Embedding with Metadata for Question Retrieval in Community Question Answering. In Associations for Computational Linguistics, 2015.<|endoftext|>City Council is making another run at refining the regulations surrounding MMJ outlets. A committee led by Councilwoman Jeanne Robb is working to define, via zoning, an \u201cembedded commercial district\u201d. These are the small business districts in the middle of residential neighborhoods. The plan is to further limit MMJ operations in those districts. WHNA members should phone or email Councilwoman Sandoval to find out whether the district at 32nd and Lowell will be included and to voice their opinions on the matter.\nAs new zoning was implemented in residential areas over the past two years, deadlines for using the previous zoning were included in the adoption ordinances. Most of those deadlines have now passed but outstanding permits based on the old zoning may not have been cancelled. The planning department is slowly working through that backlog. If you have questions about properties that may have permits that have exceeded their life expectancy, bring those to the attention of Councilwoman Sandoval\u2019s office to expedite a proper conclusion.<|endoftext|>The nose of cats: pay attention to your changes!\nIs it normal for a cat to have a dry nose? Why do cats get their nose wet? Around the nose of cats circulates the same myth as in the case of dogs and is none other than to assume that, by touching it, you can determine temperature of the animal and, therefore, its state of health.\nThis myth is so widespread among cat caregivers that we are going to dedicate this Animal Expert article to explain where this idea may have come from and what does it mean, really, the nose when assessing the health status of our cat. Do you think it is normal for a cat to have a dry nose? Keep reading!\nIt is true that, on a regular basis, touch a cat's nose We will feel it wet and cold. But it is also normal for the cat to have a dry nose, without implying any pathology or, therefore, being considered an alarm signal. So why does my cat have a dry nose? Because the nose will change its state throughout the day depending on the environment.\nFor example, if our cat is sunbathing or is near a source of heat, it is likely that its nose is dry and hot, without involving anything more than a reflection of the environment, without relation to its physical state. Therefore, the answer to our question is yes, that is, yes It is normal for a cat to have a dry nose. So why is it said that a dry nose is synonymous with a sick cat? We see it in the next section.\nWe have said that it is normal for a cat to have a dry nose, but it is also true that a sick cat is likely to have a dry and hot nose. Perhaps from this assessment derives the myth that relates the dryness of the nose with the pathology. To determine if our cat is sick or not we should look at other symptoms, not just the state of his nose.\nFor example, if our cat is decayed and has a dry nose, it may be yes have a fever and is suffering some pathological process. But to know its temperature the only reliable way is to measure the temperature of the cat using a thermometer which, in the cat, must be put in the rectum.\nPerhaps because of the difficulty of this maneuver, most caregivers prefer that it is the veterinarian who checks the temperature. For those who take it at home it is important to know that the normal temperature of cats is between 37.8 and 39.2 \u00b0 C.\nIn the same way that a dry and hot nose does not imply fever, it is not synonymous with dehydration. If we want to check the hydration status of our cat, the easiest and most effective way to do so is to watching your skin. If we stretch the cross zone, in a well hydrated cat it returns to its place immediately. On the other hand, if the skin keeps the crease and does not get smoothed, we will be facing dehydration. Of course, both fever and dehydration are veterinary consultation reason.\nCracks, grooves, peeling and / or injuries without bleeding of that style.\nBlack crust on the cat's nose.\nWounds, even if they are small.\nSecretions, of any color and consistency. Sometimes it can be a small amount of mucus that remains dry around the nostrils.\nAll these signs are going to require veterinary review since they can indicate that our cat is suffering from a respiratory condition such as a rhinotracheitis (viral infection), a dermatological problem or even a carcinogenic process.\nIt is important to highlight that most cats have the pink noseHowever, it may happen that there is a color change in the cat's nose or that the cat's nose itself turns white. Although at first it is not an indication of disease, whenever it is observed accompanied by other symptoms you should consult with our trusted veterinarian.\nIf you want to read more articles similar to Is it normal for a cat to have a dry nose?, we recommend you go to our Other health problems section.\nNormally, when from one day to another you notice that Your cat's nose has a wound, possibly have been caused by an external factor. It might have been done a scratch himself or another cat In a fight.\nIn that case it will be important to disinfect the wound, but also go to the veterinarian. Remember that If a stray cat has attacked your pet, it may have infected feline AIDS.\nThat your cat has the dry truffle does not have to mean that he is sick, or have a fever if it is also hot.\nTo the cats they love rubbing against things and that can make your nose dry or wet for a moment, as if they clean themselves with their legs.\nChanges in temperature when going outside can cause these same effects, but in none of the cases does it have to mean anything serious.\nHowever, If these symptoms recur continuously and, in addition, you notice changes in your cat's habits, there may be a problem That needs veterinary attention. You must be very aware of this!\nThe truffles of the pussycat They can be of different colors depending on the breed.\nIt may happen that the cats' nose changes color, especially if it is light in color, to a more intense tone. This can simply mean a variation of the cat's blood pressure, but"
    },
    {
        "entity": "Minjoon Seo",
        "step": 21860,
        "passage": " organic. Sheep are required to be able to graze, and growers can not use pesticides, antibiotics, hormonal agents, and other chemicals.\nThe Global Standard for Organic Textiles was developed to ensure the natural status of fabrics from the harvesting of raw materials through ecologically and socially accountable production, including labeling, to supply a reliable warranty to the customer.\nThis accreditation suggests they have actually assessed that the production procedure promotes and considers environmental impacts and protects forest biodiversity.<|endoftext|>Through informal dialogue and presentations, the #CritLib post-conference workshop and skillshare will examine how Michigan's academic library community is currently meeting the needs of Michigan's vulnerable communities and how the greater library community can work together to stand up for social justice.\nParticipants will grow in their understanding of critical librarianship and how to break down silos in their own work. Participants will be able to place their work and their library in broader contexts of expanding social justice for librarians, staff, students, and patrons.\nWe believe everyone will benefit, yet those who have an interest in critical librarianship, in administration, or public-facing positions will gain the most benefits.\nIf you have a question you want our panelists to answer please send them in advance to Grace Morris (thegracemorris@gmail.com). We will take questions during the workshop if time allows.\nCost is free to all conference attendees but pre-registration is required.<|endoftext|>After only two weeks of training, the 2018 Varsity Badminton team hosted an early-season invitational in the Palestra. Neuchatel Junior College and Inter Community School Zurich brought 28 players to compete against the Tigers. The Singles tournament results were solid for the Lady Tigers, who won the event the past two years. Captain MV Ramos '19 and teammate Margarita Ukleina '19 dominated their matches in the pool play. Later on, they would find themselves fighting it out in the championship match, with Uklieina edging out Ramos by two points. Newcomers Heather Hines '19 and Hajir Qureshi '20 also proved that they had the skills and determination. Each won important team points by beating opponent after opponent. In the Doubles tournament, Ukleina and Ramos came from behind to defeat rival ICSZ and claim the gold medal. At the end, with a combined team effort, the Lady Tigers remained the undefeated champions for the third straight year.\nIn the Boys tournament, returners Matt Meng '21, Minjoon Seo '19, and Giulio Bianco '21 showed off their smashes, fake shots, and consistency in each of their pool play games and finished at the top of their groups. Meng continued his winning streak all the way to the finals, where he lost by a narrow margin to his ICSZ opponent. Seo and Bianco were tested in the playoffs and endured some long rallies and games. All the players got some great opportunities and were able to push themselves on the court and support one another throughout the day. The boys ended the tournament with a solid 2nd-place finish.\nCongrats to all the players. The next competition will be in Zurich as ICSZ will host its invitational after the Winter Holiday.<|endoftext|>// SPDX-License-Identifier: MIT\n\npragma solidity 0.6.2;\n\nimport |||EMAIL_ADDRESS||| import \"./ERC165.sol\";\nimport \"./ERC721Enumerable.sol\";\n\ncontract ERC721Metadata is ERC165, ERC721Enumerable {\n    string private _name;\n    string private _symbol;\n    string private _baseURI;\n\n    // mapping Token ID => Token URI\n    mapping(uint256 => string) private _tokenURIs;\n\n    /*\n     *     bytes4(keccak256('name()')) == 0x06fdde03\n     *     bytes4(keccak256('symbol()')) == 0x95d89b41\n     *     bytes4(keccak256('tokenURI(uint256)')) == 0xc87b56dd\n     *\n     *     => 0x06fdde03 ^ 0x95d89b41 ^ 0xc87b56dd == 0x5b5e139f\n     */\n    bytes4 private constant _INTERFACE_ID_ERC721_METADATA = 0x5b5e139f;\n\n    constructor(\n        string memory name,\n        string memory symbol,\n        string memory baseURI\n    ) public {\n        _name = name;\n        _symbol = symbol;\n        _baseURI = baseURI;\n\n        _registerInterface(_INTERFACE_ID_ERC721_METADATA);\n    }\n\n    /**\n     * @dev Returns the token name.\n     */\n    function name() external view returns (string memory) {\n        return _name;\n    }\n\n    /**\n     * @dev Returns the token symbol.\n     */\n    function symbol() external view returns (string memory) {\n        return _symbol;\n    }\n\n    /**\n     * @dev Returns the base URI set via {_setBaseURI}.\n     */\n    function baseURI() external view returns (string memory) {\n        return _baseURI;\n    }\n\n    /**\n     * @dev Returns an URI for a given token ID\n     * Throws if the token ID does not exist. It may return an empty string.\n     * @param tokenId uint256 ID of the token to query\n     */\n    function tokenURI(uint256 tokenId) external view returns (string memory) {\n        require(\n            _exists(tokenId),\n            \"ERC721Metadata: URI query for nonexistent token\"\n        );\n\n        return _tokenURIs[tokenId];\n    }\n\n    /**\n     * @dev Sets `_tokenURI` for `tokenId`.\n     */\n    function _setTokenURI(uint256 tokenId) internal virtual {\n        require(\n            _exists(tokenId),\n            \"ERC721Metadata: URI set of nonexistent token\"\n        );\n        _tokenURIs[tokenId] = string(\n            abi.encodePacked(_baseURI, Strings.toString(tokenId))\n        );\n    }\n\n    /**\n     * @dev Internal function to set the base URI for all token IDs. It is\n     * automatically added as a prefix to the value returned in {tokenURI},\n     * or to the token ID if {tokenURI} is empty.\n     */\n    function _setBaseURI(string memory baseURI_) internal virtual {\n        _baseURI = baseURI_;\n    }\n}<|endoftext|>King Lion in a hand painted oil painting on canvas that shows the king of the jungle, the Lion. This pop art is filled with vibrant colors that can easily entice onlookers. King Lion would...\nLion is a colourful pop art of the magnificent king of the jungle. This beautifully handcrafted oil painting is filled with vibrant colors. It is definitely a must-have for those who are...\nGiraffe is a pop art that shows an image of one of the amazing mammals in the animal kingdom. This cool artwork is bursting with vibrant colors. If you are looking for an animal-inspired...\nSophistication is a pop art that shows the sophisticated side of a woman. The painting is filled with different floral patterns. This contemporary oil painting is ideal for those who are...\nElephant is one of the animal wall art available in our huge collection. This pop art shows a silhouette of an elephant adorned with different colourful floral patterns. This elephant wall art...\nMosaic is a hand painted abstract canvas art that highlights tiles of different colours. This artwork is definitely eye-catching due to its impressive visuals. This wall art deserves to be displayed...\nPug is a colourful hand painted wall art of an adorable furball. If you are into pop art and dogs, this work of art will surely entice you. This masterpiece deserves to be hanged on an art and...\nZebra is one of the best pop art in our animal paintings collection it shows an image of a zebra having neon-coloured stripes, instead of the traditional black and white stripes. This piece of...\nMan's Best Friend is a hand painted oil painting that shows an image of the man's best friend, the dog. This modern wall art is filled with enticing, vibrant colors. If you are looking to...\nEn Vogue is a contemporary canvas painting that depicts a woman as a trendsetter. The painting is filled with different floral patterns that symbolize the beauty of a woman. This is ideal...\nAllure is a hand painted wall art that shows the charm of an Asian woman. Known for being powerfully and mysteriously beautiful, Asian women are known for being one of the most attractive...\nHer is a pop art that shows an image of a fierce woman. Through the years, women have been empowered and since then played a huge role in society. This contemporary oil painting on canvas is an...\nThe King is a pop art that shows an image of a lion in vibrant colors. This animal artwork is greatly recommended for people who love animals and art. If you are looking for an oil painting on canvas to decorate your bare walls, this is one of the best options you have.\nCall us on 1300 90 21 53 and talk to your friendly art customer service representative.\nFraming Options: All 2016 New Art paintings come stretched and Ready to hang.<|endoftext|>Dear Friends: after almost five years as a Facebook user, I have decided to"
    },
    {
        "entity": "Minjoon Seo",
        "step": 22835,
        "passage": " Aware Neural Machine Translation\nKehai Chen, Rui Wang, Masao Utiyama and Eiichiro Sumita\n\nContextual Embeddings: When Are They Worth It?\nSimran Arora, Avner May, Jian Zhang and Christopher R\u00e9\n\nContextual Neural Machine Translation Improves Translation of Cataphoric Pronouns\nKayYen Wong, Sameen Maruf and Gholamreza Haffari\n\nContextualized Sparse Representations for Real-Time Open-Domain Question Answering\nJinhyuk Lee, Minjoon Seo, Hannaneh Hajishirzi and Jaewoo Kang\n\nContextualizing Hate Speech Classifiers with Post-hoc Explanation\nBrendan Kennedy, Xisen Jin, Aida Mostafazadeh Davani, Morteza Dehghani and Xiang Ren\n\nContrastive Self-Supervised Learning for Commonsense Reasoning\nTassilo Klein and Moin Nabi\n\nControlled Crowdsourcing for High-Quality QA-SRL Annotation\nPaul Roit, Ayal Klein, Daniela Stepanov, Jonathan Mamou, Julian Michael, Gabriel Stanovsky, Luke Zettlemoyer and Ido Dagan\n\nConversational Word Embedding for Retrieval-Based Dialog System\nWentao Ma, Yiming Cui, Ting Liu, Dong Wang, Shijin Wang and Guoping Hu\n\nCrawling and Preprocessing Mailing Lists At Scale for Dialog Analysis\nJanek Bevendorff, Khalid Al Khatib, Martin Potthast and Benno Stein\n\nCrossing Variational Autoencoders for Answer Retrieval\nWenhao Yu, Lingfei Wu, Qingkai Zeng, Shu Tao, Yu Deng and Meng Jiang\n\nDeeBERT: Dynamic Early Exiting for Accelerating BERT Inference\nJi Xin, Raphael Tang, Jaejun Lee, Yaoliang Yu and Jimmy Lin\n\nDesigning Precise and Robust Dialogue Response Evaluators\nTianyu Zhao, Divesh Lala and Tatsuya Kawahara\n\nDialogue State Tracking with Explicit Slot Connection Modeling\nYawen Ouyang, Moxin Chen, Xinyu Dai, Yinggong Zhao, Shujian Huang and Jiajun Chen\n\nDo Transformers Need Deep Long-Range Memory?\nJack Rae and Ali Razavi\n\nDo you have the right scissors? Tailoring Pre-trained Language Models via Monte-Carlo Methods\nNing Miao, Yuxuan Song, Hao Zhou and Lei Li\n\nDoes Multi-Encoder Help? A Case Study on Context-Aware Neural Machine Translation\nBei Li, Hui Liu, Ziyang Wang, Yufan Jiang, Tong Xiao, Jingbo Zhu, Tongran Liu and Changliang Li\n\nDon\u2019t Eclipse Your Arts Due to Small Discrepancies: Boundary Repositioning with a Pointer Network for Aspect Extraction\nZhenkai Wei, Yu Hong, Bowei Zou, Meng Cheng and Jianmin Yao\n\nDscorer: A Fast Evaluation Metric for Discourse Representation Structure Parsing\nJiangming Liu, Shay B. Cohen and Mirella Lapata\n\nDynamic Memory Induction Networks for Few-Shot Text Classification\nRuiying Geng, Binhua Li, Yongbin Li, Jian Sun and Xiaodan Zhu\n\nDynamic Sampling Strategies for Multi-Task Reading Comprehension\nAnanth Gottumukkala, Dheeru Dua, Sameer Singh and Matt Gardner\n\nDynamically Adjusting Transformer Batch Size by Monitoring Gradient Direction Change\nHongfei Xu, Josef van Genabith, Deyi Xiong and Qiuhui Liu\n\nEfficient strategies for hierarchical text classification: external knowledge and auxiliary tasks\nKervy Rivas Rojas, Gina Bustamante, Arturo Oncevay and Marco Antonio Sobrevilla Cabezudo\n\nEmbarrassingly Simple Unsupervised Aspect Extraction\nSt\u00e9phan Tulkens and Andreas van Cranenburgh\n\nEnabling Language Models to Fill in the Blanks\nChris Donahue, Mina Lee and Percy Liang\n\nEncoder-Decoder Models Can Benefit from Pre-trained Masked Language Models in Grammatical Error Correction\nMasahiro Kaneko, Masato Mita, Shun Kiyono, Jun Suzuki and Kentaro Inui\n\nENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation\nLifu Tu, Richard Yuanzhe Pang, Sam Wiseman and Kevin Gimpel\n\nEnhancing Machine Translation with Dependency-Aware Self-Attention\nEmanuele Bugliarello and Naoaki Okazaki\n\nEnhancing Pre-trained Chinese Character Representation with Word-aligned Attention\nYanzeng Li, Bowen Yu, Xue Mengge and Tingwen Liu\n\nEnriched In-Order Linearization for Faster Sequence-to-Sequence Constituent Parsing\nDaniel Fern\u00e1ndez-Gonz\u00e1lez and Carlos G\u00f3mez-Rodr\u00edguez\n\nEntity-Aware Dependency-Based Deep Graph Attention Network for Comparative Preference Classification\nNianzu Ma, Sahisnu Mazumder, Hao Wang and Bing Liu\n\nEstimating Mutual Information Between Dense Word Embeddings\nVitalii Zhelezniak, Aleksandar Savkov and Nils Hammerla\n\nEvaluating Dialogue Generation Systems via Response Selection\nShiki Sato, Reina Akama, Hiroki Ouchi, Jun Suzuki and Kentaro Inui\n\nEvaluating Robustness to Input Perturbations for Neural Machine Translation\nXing Niu, Prashant Mathur, Georgiana Dinu and Yaser Al-Onaizan\n\nEvery Document Owns Its Structure: Inductive Text Classification via Graph Neural Networks\nYufeng Zhang, Xueli Yu, Zeyu Cui, Shu Wu, Zhongzhen Wen and Liang Wang\n\nExpBERT: Representation Engineering with Natural Language Explanations\nShikhar Murty, Pang Wei Koh and Percy Liang\n\nExploiting Personal Characteristics of Debaters for Predicting Persuasiveness\nKhalid Al Khatib, Michael V\u00f6lske, Shahbaz Syed, Nikolay Kolyada and Benno Stein\n\nExploring Content Selection in Summarization of Novel Chapters\nFaisal Ladhak, Bryan Li, Yaser Al-Onaizan and Kathy McKeown\n\nFact-based Content Weighting for Evaluating Abstractive Summarisation\nXinnuo Xu, Ond\u0159ej Du\u0161ek, Jingyi Li, Verena Rieser and Ioannis Konstas\n\nFatality Killed the Cat or: BabelPic, a Multimodal Dataset for Non-Concrete Concepts\nAgostina Calabrese, Michele Bevilacqua and Roberto Navigli\n\nFew-Shot NLG with Pre-Trained Language Model\nZhiyu Chen, Harini Eavani, Wenhu Chen, Yinyin Liu and William Yang Wang\n\nFLAT: Chinese NER Using Flat-Lattice Transformer\nXiaonan Li, Hang Yan, Xipeng Qiu and Xuanjing Huang\n\nGAN-BERT: Generative Adversarial Learning for Robust Text Classification with a Bunch of Labeled Examples\nDanilo Croce, Giuseppe Castellucci and Roberto Basili\n\nGeometry-aware domain adaptation for unsupervised alignment of word embeddings\nPratik Jawanpuria, Mayank Meghwanshi and Bamdev Mishra\n\nGive Me Convenience and Give Her Death: Who Should Decide What Uses of NLP are Appropriate, and on What Basis?\nKobi Leins, Jey Han Lau and Timothy Baldwin\n\nGlyph2Vec: Learning Chinese Out-of-Vocabulary Word Embedding from Glyphs\nHong-You Chen, SZ-HAN YU and Shou-de Lin\n\nGPT-too: A language-model-first approach for AMR-to-text generation\nManuel Mager, Ram\u00f3n Fernandez Astudillo, Tahira Naseem, Md Arafat Sultan, Young-Suk Lee, Radu Florian and Salim Roukos\n\nHow Can We Accelerate Progress Towards Human-like Linguistic Generalization?\nTal Linzen\n\nHypernymy Detection for Low-Resource Languages via Meta Learning\nChanglong Yu, Jialong Han, Haisong Zhang and Wilfred Ng\n\nIdentifying Principals and Accessories in a Complex Case based on the Comprehension of Fact Description\nYakun Hu, Zhunchen Luo and Wenhan Chao\n\nImplicit Discourse Relation Classification: We Need to Talk about Evaluation\nNajoung Kim, Song Feng, Chulaka Gunasekara and Luis Lastras\n\nImproved Speech Representations with Multi-Target Autoregressive Predictive Coding\nYu-An Chung and James Glass\n\nImproving Entity Linking through Semantic Reinforced Entity Embeddings\nFeng Hou, Ruili Wang, Jun He and Yi Zhou\n\nImproving"
    },
    {
        "entity": "Minjoon Seo",
        "step": 23490,
        "passage": " your needs.\nOverall, just because one company considers you or your property \"high risk\" doesn't mean every provider will. As we mentioned, it's best to attempt to get standard coverage first because you can save money and get better protection than you could with a non-standard policy.\nWe've provided you with some companies that offer non-standard insurance for different situations. However, there may be alternative options within your state. Also, some non-standard property insurance companies focus on a specific type of coverage, so you may need to supplement your standard policy.\nFor example, in Texas, homes on the Gulf Coast are often denied wind and hail claims because of hurricane damage. However, the Texas Windstorm Insurance Association (TWIA) provides coverage as an \"insurer of last resort.\" Another example would be earthquake insurance in California.\nAgain, be sure to shop around between different providers. Never assume that the first quote you get is the best one. It may take more time and effort upfront, but you could save a lot of money in the long-term.\nBefore signing up for a policy, it helps to know both the benefits and disadvantages of non-standard insurance.\nPro: Easier to Get Approved - If you're a high-risk individual, you'll likely get denied coverage from all the major insurance providers. However, non-standard insurance companies specialize in saying yes to people like you. Some protection is better than nothing, especially when disaster strikes.\nCon: More Expensive - Overall, you'll need to pay higher premiums and deductibles with a non-standard insurance plan. If you have a tight budget, you may need to assess your needs accordingly.\nPro: Avoid Lapses in Coverage - As we mentioned, insurance lapses can be problematic and make you an even higher risk. Getting non-standard insurance now could help you get better coverage later on.\nAs you can see, non-standard insurance can provide peace of mind and enable you to protect your belongings. As long as you take the time to shop around and you know what to expect, you can get suitable coverage for everything that's important to you.<|endoftext|>Firing squad have on Monday executed Alshabaab media representative Hassan Hanafi.\nSenior security officers,members of the public and families of Journalists killed were presented during the execution.\nHanafi whose death sentence appeal by military court was rejected said he was behind the attacks that was targeted on Somali Journalists in 2009 to 2011 in Mogadishu.\nSeveral Journalists were killed under his watch when he was part of Alshabaab media representative in Somalia.\nHassan Hanafi was detained in Kenya and extradited to Somalia for prosecution in 2014 for crimes against the media.\nHuman right groups have condemned the execution mainly carried out by the Somali military court.\n(Xogta): War-murtiyeedka Madasha Wada-tashiga Qaranka & Jadwalka Doorashooyinka.<|endoftext|>Myst is a classic video game graphic adventure. Published in 1983, and selling over six million copies, it pre-dates many modern adventure games and created a new genre for gaming. Exploring by clicking in the world to move, you use a special book to...\nWe Were Here is a series of puzzle adventures where you and a fellow explorer awake inside the sinister Castle or similar location with no way out. Play is by exploring your location to find clues and solve puzzles. Uniquely, the puzzles you encounter...<|endoftext|>Agreed. As much as stadium projects are good jumpstart for rehabbing polluted industrial lands - I'm still a big believer that the West Harbour will, in the long run, be better off.\nPerhaps a more functional used community centre would more beneficial, while tying up less lands for active development that results in real growth.<|endoftext|>Samsung Electronics has uncovered a new plan for shaping the future with AI and semiconductors by unveiling new milestones in AI-based semiconductor and material innovation. The tech goliath disclosed this today at the ongoing Samsung AI Forum 2022.\nSamsung AI Forum is an annual AI event hosted by Samsung Electronics where world-renowned academics, researchers, and industry experts will come together to share their insights on the future of artificial intelligence, AI.\nCurrently, the event is hosted at the Samsung Advanced Institute of Technology with over 1,200 attendees. This year, Samsung AI Forum begins today, November 8th, and will conclude tomorrow, November 9th. This is the first time in three years that the event will be held in person due to the emergence of the novel coronavirus.\nUnder the theme of \u201cShaping the Future with AI and Semiconductor,\u201d Samsung AI experts discuss the future direction of AI research that will create new milestones in AI-based semiconductor and material innovation.\nProfessor Yoshua Bengio of the University of Montreal, Canada, shared his latest research in a keynote presentation, \u201cWhy We Need Amortized, Causal and Bayesian World Models.\u201d In causal models for AI that investigate theories and plan experiments in the realm of science and general AI, he emphasized the use of amortized inference and the Bayesian approach.\nMeanwhile, in his opening remarks, Jong-Hee (JH) Han, Vice Chairman, CEO, and Head of the Device Experience (DX) Division at Samsung Electronics, said AI technology would provide better convenience and new experiences for all.\nIn the \u201cAI for R&D Innovation\u201d session, research leaders at SAIT, including the Executive Vice President and Head of SAIT\u2019s AI Research Center, Changkyu Choi, shared the status and vision of Samsung\u2019s research on AI. In particular, they talked about how AI technology will affect industries like semiconductors and material development.\nMinjoon Seo, a professor at KAIST, and Hyunoh Song, a professor at Seoul National University, gave a presentation on the most recent research accomplishments in AI algorithms in a session titled \u201cRecent Advances of AI Algorithms.\u201d This included a large language model-based interface for ultra-accurate semantic search.\nHowever, according to the firm, day two is themed \u201cScaling AI for the Real World.\u201d There Samsung is expected to share the development direction of future AI technologies that will significantly affect our lives, including hyperscale AI, digital humanities, and robotics.\nSebastian Seung, President and Head of Samsung Research will give a keynote on the \u201cfirst steps of an effort to improve upon classical brain theories by optimizing biologically plausible unsupervised learning algorithms\u201d and a welcoming remark.\nProfessor Terrence Sejnowski of the University of California San Diego in the United States, who founded NeurIPS, the most prestigious AI conference in the world, will speak about the intelligence of hyper-scale language models based on experimental studies examining the existence of intelligence in hyper-scale language models.\nIn all, professor Seungwon Hwang of Seoul National University will talk about how causality, evidentiality, and other types of information can be used to strengthen hyper-scale language models. Participants will also have the chance to view several demos and research posters created by the Global AI Center at the booth, where they may speak with the researchers in person.<|endoftext|>Belarusian dictator Alexander Lukashenko used a speech on Saturday to threaten military retaliation against anybody who attacked his country, as tensions over the war in neighbouring Ukraine remained high.\nSpeaking on the eve of the country's Independence Day, Lukashenko said that he had ordered his armed forces to target \"the decision-making centres\" of Western capitals in the event of an attack on Belarus, adding: \"Don't touch us - and we won't touch you,\" according to state news agency Belta.<|endoftext|>Leonard Person Jr. has experienced plenty of success in his career, and is grateful for how far he\u2019s come in just a few short years in the real estate and credit industries. But, even with all of his professional success, there\u2019s nothing he\u2019s more passionate about than giving back to others.\nLeonard has taught countless people the nuances of real estate investing for free, has bought homes for his parents, donated money and clothes to those in need, and has even loaned money to friends and family expecting nothing in return. He\u2019s done his fair share of giving back in recent times, and he\u2019s still more than willing to help someone to this day.\nLeonard\u2019s business also gives back to the community in a tremendous way. He is the CEO of MyHouseGram.com, a firm that specializes in teaching strategic real estate investing methods including quiet title litigation, wholesale acquisition deals, buying and selling non performing notes, and the basics of flipping homes. His firm also offers credit repair services and business lines of credit as a service, helping clients secure the funding necessary to take action on his real estate teachings.\nHis company\u2019s ability to offer so many financial and investment services under one roof gives them a massive advantage in the industry, as his company\u2019s core values have its client\u2019s best interests in mind. His company\u2019s services allow customers to create multiple streams of income through owning properties without mortgages. This, Leonard says, is the key to true financial success.\nLeonard is also the author of \u201cHood Estate The Manual\u201d, a book that gives the urban community an idea on how to flip properties for massive profits and build real wealth by leveraging credit. He dives into his experiences flipping houses and how he\u2019s learned along the way, including how he was able to flip one of his first properties for 180,000 in profit after taxes.\nLeonard has also learned to become incredibly smart with his money, and is able to write off as many expenses as he can to keep his taxes down. But, he knows all too well that"
    },
    {
        "entity": "Minjoon Seo",
        "step": 25213,
        "passage": " to favor the true solution. The model sometimes gives the wrong prediction\u2014for example, at t=16k, and changes its prediction from the true solution to the wrong solution, \u201837-36\u2019\u2014but again changes its prediction to be a true solution afterward. In addition, its intermediate wrong solution, \u201837-36\u2019 indicates the model was confused with distinguishing the longest field goal of Rob Bironas (40 vs. 37), which is an understandable mistake.\nWe also compare the predictions from the model with our method to those from the model with MML, which is shown in Appendix C.\nQuality of the predicted solution.\nWe analyze if the model outputs the correct solution, since the solution executing the correct answer could be spurious. First, on NarrativeQA and DROPnum, we manually analyze 50 samples from the development set and find that 98% and 92% of correct cases produce the correct solution respectively. Next, on WikiSQL, we compare the predictions from the model to the annotated SQL queries on the development set. This is possible because gold SQL queries are available in the dataset for the full supervision. Out of 8,421 examples, 7,110 predictions execute the correct answers. Among those, 88.5% of the predictions are exactly same as the annotated queries. Others are the cases where (i) both queries are correct, (ii) the model prediction is correct but the annotated query is incorrect, and (iii) the annotated query is correct and the model prediction is spurious. We show a full analysis in Appendix C.\nRobustness to the noise in |Z|.\nSometimes noise arises during the construction of |Z|, such as |Z| constructed based on ROUGE-L for NarrativeQA. To explore the effect of noise in Z, we experiment with more noisy solution set by picking all the spans with scores that is equal to or larger than the 5th highest. The new construction method increases |Z| from 4.3 to 7.1 on NarrativeQA. The result by MML objective drops significantly (56.07\u219251.14) while the result by ours drops marginally (58.77\u219257.97), suggesting that MML suffers more with a noisier Z while ours is more robust.\nIn this paper, we demonstrated that, for many QA tasks which only provide the answer text as supervision, it is possible to precompute a discrete set of possible solutions that contains one correct option. Then, we introduced a discrete latent variable learning algorithm which iterates a procedure of predicting the most likely solution in the precomputed set and further increasing the likelihood of that solution. We showed that this approach significantly outperforms previous approaches on six QA tasks including reading comprehension, open-domain QA, discrete reasoning task and semantic parsing, achieving absolute gains of 2\u201310% and setting the new state-of-the-art on five well-studied datasets.\nThis research was supported by ONR (N00014-18-1-2826, N00014-17-S-B001), DARPA N66001-19-2-403, NSF (IIS-1616112, IIS-1252835, IIS-1562364), ARO (W911NF-16-1-0121), an Allen Distinguished Investigator Award, Samsung GRO and gifts from Allen Institute for AI, Google and Amazon.\nThe authors would like to thank the anonymous reviewers, Eunsol Choi, Christopher Clark, Victor Zhong and UW NLP members for their valuable feedback.\nAbolafia et al. (2018) Daniel A Abolafia, Mohammad Norouzi, Jonathan Shen, Rui Zhao, and Quoc V Le. 2018. Neural program synthesis with priority queue training. arXiv preprint arXiv:1801.03526.\nAgarwal et al. (2019) Rishabh Agarwal, Chen Liang, Dale Schuurmans, and Mohammad Norouzi. 2019. Learning to generalize from sparse and underspecified rewards. In ICML.\nAlberti et al. (2019) Chris Alberti, Kenton Lee, and Michael Collins. 2019. A BERT baseline for the Natural Questions. arXiv preprint arXiv:1901.08634.\nArtzi and Zettlemoyer (2013) Yoav Artzi and Luke Zettlemoyer. 2013. Weakly supervised learning of semantic parsers for mapping instructions to actions. In ACL.\nBerant et al. (2013) Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic parsing on Freebase from question-answer pairs. In EMNLP.\nChen et al. (2017) Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading Wikipedia to answer open-domain questions. In ACL.\nClarke et al. (2010) James Clarke, Dan Goldwasser, Ming-Wei Chang, and Dan Roth. 2010. Driving semantic parsing from the world\u2019s response. In CoNLL.\nDong and Lapata (2018) Li Dong and Mirella Lapata. 2018. Coarse-to-fine decoding for neural semantic parsing. In ACL.\nDua et al. (2019) Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner. 2019. DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs. In NAACL.\nHe et al. (2019) Pengcheng He, Yi Mao, Kaushik Chakrabarti, and Weizhu Chen. 2019. X-SQL: reinforce schema representation with context. arXiv preprint arXiv:1908.08113.\nHurley and Rickard (2009) Niall Hurley and Scott Rickard. 2009. Comparing measures of sparsity. IEEE Transactions on Information Theory.\nHwang et al. (2019) Wonseok Hwang, Jinyeung Yim, Seunghyun Park, and Minjoon Seo. 2019. A comprehensive exploration on WikiSQL with table-aware word contextualization. arXiv preprint arXiv:1902.01069.\nIyyer et al. (2017) Mohit Iyyer, Wen-tau Yih, and Ming-Wei Chang. 2017. Search-based neural structured learning for sequential question answering. In ACL.\nJoshi et al. (2017) Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke Zettlemoyer. 2017. TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension. In ACL.\nKadlec et al. (2016) Rudolf Kadlec, Martin Schmid, Ondrej Bajgar, and Jan Kleindienst. 2016. Text understanding with the attention sum reader network. In ACL.\nKo\u010disk\u1ef3 et al. (2018) Tom\u00e1\u0161 Ko\u010disk\u1ef3, Jonathan Schwarz, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, G\u00e1bor Melis, and Edward Grefenstette. 2018. The NarrativeQA reading comprehension challenge. TACL.\nKrishnamurthy et al. (2017) Jayant Krishnamurthy, Pradeep Dasigi, and Matt Gardner. 2017. Neural semantic parsing with type constraints for semi-structured tables. In EMNLP.\nKwiatkowski et al. (2019) Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Change, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natural questions: a benchmark for question answering research. TACL.\nLee et al. (2019) Kenton Lee, Ming-Wei Chang, and Kristina Toutanova. 2019. Latent retrieval for weakly supervised open domain question answering. In ACL.\nLiang et al. (2017) Chen Liang, Jonathan Berant, Quoc Le, Kenneth D Forbus, and Ni Lao. 2017.\nLiang et al. (2018) Chen Liang, Mohammad Norouzi, Jonathan Berant, Quoc V Le, and Ni Lao. 2018. Memory augmented policy optimization for program synthesis and semantic parsing. In NIPS.\nLin (2004) Chin-Yew Lin. 2004. ROUGE: A package for automatic evaluation of summaries. Text Summarization Branches Out.\nMin et al. (2019) Sewon Min, Eric Wallace, Sameer Singh, Matt Gardner, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2019. Compositional questions do not necessitate multi-hop reasoning. In ACL.\nNishida et al. (2019) Kyosuke Nishida, Itsumi Saito, Kosuke Nishida, Kazutoshi Shinoda, Atsushi Otsuka, Hisako Asano, and Junji Tomita. 2019. Multi-style generative reading comprehension. In ACL.\nPaszke et al. (2017) Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. 2017.\nAutomatic differentiation in PyTorch.\nRajpur"
    },
    {
        "entity": "Minjoon Seo",
        "step": 25456,
        "passage": ".\nA dual distortion device delivers six distinct modes varying from analog pre-amp distortions, fuzzbox style distortion, and conducts waveshaping.\nA great deal of time and work was invested in Electra X 2.9 Serial Key features. Therefore, Electra X inserts an effects section spanning from 18 high-quality effect processors and finer songs such as Delayed, Multitap delay, Quintet, Smart-unison, Trance gate, Chorus, Flinger, and Phaser.\nElectra X Plug-in features also contain a modulation area. However, it permits the usage of punchy and audio-rate speed.\nModulation is transmitted to high-quality LFOs which may be matched to your track\u2019s BPM. LFO will employ to create rhythmic sequences or bespoke waveforms.\nHence, by applying the adjustable modulation matrix, we may verify the ideal sound. It is straightforward to use and delivers an instantaneous explanation of the active modulations.\nThis part is used to produce and perform arpeggios. ElectraX\u2019s multi-layers can handle four feature synthesizers with four arpeggiators.\nThus, it allows you to build as basic or as complicated sequences with multiple instruments as you wish.\nThe arpeggiator has several complex capabilities such as auto-chords, pitch-slides, legato, swing-glide, and matrix integration.\nHyper Unison, Phaser FB, Phaser Stereo, Vibrato, Vibrato Stereo, Tremelo, Tremolo Stereo, Chorus, Ensemble, Flanger, Rotary, Phaser, Compressor, Ampsim, Trancegate, Equalizer, Punch, Surround Encode, Vocoder.\nA huge interface is accessible beside the standard scale now.\nIt is able to pick between 6 GUI sizes by clicking on \u2018SIZE\u2019.\nThe plugin recognizes the screen resolution and determines the appropriate size automatically.\nThe sensor, the OSC-display, the LFO-display, and the envelope-display are displayed when automation or Midi-learn is employed.\nPitch wheel and Modwheel are animated whenever the patch browser is visible.\nAdded Notarisation for the installs on Mac.\nSigning on the Mac, as new hosts may require it to be able to execute plugins.\nCompatibility with macOS Catalina.\nCompletely updated AudioUnit interface.\nThe plugin and songs are loading, storing, opening, and shutting faster.\nBetter interoperability with other plugins.\nMore intuitive handling of sample loops.\nBetter explanations for certain tool-tips.\nMany tiny upgrades for the user interface.\nMore contrast again for pitch-wheel and version in the patch-browser.\nMore precise timing for Midi-events.\nMore precise processing of the Midi-pitch wheel.\nHow to Active ElectraX VST Crack?\nDownload ElectraX VST Crack For Free.<|endoftext|>We examine the major organs, most deaths come from some problem in one of them. I usually begin by opening the trachea to make sure the person hasn't choked (it's more common than you'd think) then we weight the organs in the chest and abdomen and examine them all. Then we move on to the brain. Most causes of death leave some morphological \"clue\" behind. When we can't find any, we sign it as an unknown cause of death. Sometimes histology helps, but usually if you can't find anything in the autopsy room, you won't find anything later. After a while, examining the organs becomes pretty automatic, it goes fast.<|endoftext|>Normally, we wait until the end.\nWe know that there will be some sort of resolution.\nWe can anticipate what\u2019s coming, and know that there will hopefully be a positive outcome.\nWe are not quite sure how long this tunnel is, and we can\u2019t wait for the light at the end of it.\nThis week, we will welcome students back into our school as part of a Hybrid model.\nIt\u2019s the light in the middle of the tunnel.\nStudents will be back.\nTeachers will teach students in person.\nAll students will not be there, but it\u2019s OK.\nIt\u2019s a start. Or at least some light in the middle.<|endoftext|>AIMM provides exceptional music education for inspiring drummers and percussion artists in Scottdale, Georgia. If you have a passion for music and drumming, you're in the right place.\nStudents will learn the best and most common drum grooves, work on drumming speed, rhythm, technique, and more through rigorous training targeted on technological and musical studies at our Scottdale, Ga Drum School.\nOur top-rated Scottdale Drum School provides students with the instructional environment necessary to develop their rhythm, speed, feel, technological & musical proficiency, and acquire the expertise necessary to become one of today's elite musicians.\nAIMM is one of the only Scottdale Music Colleges the blends organic drumming instrumentation with music production instruction. As an AVID Pro Tools Training Partner, AIMM offers all of the insider techniques and professional approaches when it comes to recording, mixing, and mastering. Just imagine being able to professionally mix your own drum tracks!\nWe also offer Scottdale drummers the Drumming Performance Certificate. This certificate will help you master your on-stage presence, improvisational abilities, and technical skills.\nIf you want to enroll in a Scottdale Drum School, there is no better opportunity to separate from the crowd than by enrolling at AIMM.<|endoftext|>At the annual Academic Awards Assembly on the morning of May 28, High School Academic Dean Dr. Mark Abisi announced that three seniors\u2014Virginia Italia, Katherine Kelly, and Irene Lee\u2014and four juniors\u2014Alessandra Appiani, Airi Barnes, Maria Mastronardi, and Giulia Meregalli\u2014have been inducted to the TASIS Cum Laude Society chapter. Congratulations to the seven outstanding scholars for this prestigious honor.\nFounded in 1906, the Cum Laude Society aims to promote learning and sound scholarship in secondary schools while recognizing exceptional scholastic achievement. Unlike the National Honor Society, which primarily works with public high schools in North America and strongly considers a student\u2019s leadership, service, and character, the Cum Laude Society places its greatest emphasis on a student\u2019s scholarly contributions to his or her school.\nThe new inductees will join the 10 students honored in May 2017 when TASIS became the first school in Switzerland to establish a Cum Laude Society chapter\u2014Charlotte Colombo \u201918, Hannah Gage \u201917, Kirill Krupenin \u201917, Aida Loggiodice \u201917, Niccolo McConnell \u201917, Adam Novak \u201917, Bryan Soh \u201918, Laura Vecoli \u201917, Maria Vittoria Gallina Bognetti \u201917, and Shu Ye \u201918\u2014and the eight scholars inducted last May: Raffaella Alencar Barros \u201919, Aurelia Dochnal \u201919, Anastasia Kolesnikova \u201918, Noah Plues \u201918, Zeydan Rahman \u201919, Alexander Secilmis \u201919, Minjoon Seo \u201919, and Mariko Yamada \u201919.\nExcellence, Justice, Honor. Excellence includes the concept of excellence in the moral sense and is not limited to the ideal of superiority and scholarship, nor does it involve the endeavor of competing primarily for academic goals. Justice includes the concept of what is suitable and appropriate, as well as just. Honor includes the concept of dignity and truth, as well as honor.<|endoftext|>In the current age of digital commerce and virtual businesses, we have found that security can be one of the most important tools in any computerized operation. So how can we know if the system we are using for our business needs is secure and will keep your important data protected? There are many factors to look at when determining the security of a platform. One of the most popular platforms for many offices is Microsoft 365 or Office 365. This platform has many security features built in and many more that can be customizable to each business\u2019s needs. We will examine a few of the more prevalent security measures and their benefits.\nThe most used security tool is the use of multi-factor authentication, also known as 2-factor authentication system. This is a simple tool that requires users to have more than just their username and password to log into a system or even just into certain areas of a protected system. While the username and password are still important, in a 2-factor authentication setup the user will also receive either a phone call, text message, or use an authenticator app. Microsoft and Google each have authenticator apps that users can download.\nWhen it comes to data security, employers must be vigilant in training their employees to use the security measures that are in place. Knowing how to effectively use the security measures allows companies to feel more secure in their data protection plans. Improperly trained employees can create gaps in your security and allow sensitive data to be left unprotected and exposed.\nAnother security measure in many places of business, the use of a dedicated Administrator account for all admin privileges can keep those duties and task separated from traditional daily tasks.  This keeps rogue programs and task from running amuck without being kept in check, allowing the limited user a safer work environment.\nMalware and ransomware are two areas where a business must stay on top of security to stop these threats before they get a foothold in the system. Malware can be hidden in emails and can go undetected for some time before it begins causing problems. While ransomware can be used against a company where all its data is encrypted or stolen to collect a ransom. While both types of threats can"
    },
    {
        "entity": "Minjoon Seo",
        "step": 25845,
        "passage": "\u805a\u5408\u51fd\u6570\uff1b\uff083\uff09Model_opval\uff1a\u9884\u6d4b\u8fd0\u7b97\u7b26\u3001\u6761\u4ef6\u7684\u53d6\u503c\u3002\n\n![image.png](img/1584454149724-bb5805e4-ccc8-4839-ae3b-88b57bc114f9.png)\n\n  i. \u4e09\u4e2a\u6a21\u578b\u4f7f\u7528\u76f8\u540c\u7684\u65b9\u6cd5\u6765\u8ba1\u7b97\u52a0\u6743\u95ee\u9898\u548c\u7c7b\u578b\u8868\u793a\u5f62\u5f0fHQT / COL\uff08SQLNet\u63d0\u51fa\uff09\u3002\n\n![image.png](img/1584455373728-c1827b63-14e7-4077-9204-ce4b3ae1cef8.png)\n\n  i.  MODEL_COL\u6a21\u5757\n\n\u6a21\u5757\u9700\u8981\u9884\u6d4b\u4e09\u90e8\u5206\uff1a`SELECT_COL`,\u200b `COND_num`\u548c`COND_COL` \u8fd9\u4e09\u4e2a\u90e8\u5206\u6709\u4e2a\u7279\u70b9\u90fd\u662f\u8981\u7ed3\u5408question\u548c\u8868(\u6240\u6709\u5217\u540d)\u7684\u7279\u5f81\u3002\n\n\u9884\u6d4b\u200b `SELECT_COL`: \n\n\u200b                   ![image.png](img/1584456260577-501a28ab-4990-4209-860a-5da2039b6f18.png)\n\n\u9884\u6d4b `COND_num`\uff1a\n\n![image.png](img/1584456306256-937e9b2a-2df5-4eae-8f16-615e09cb72bb.png)\n\n\u9884\u6d4b `COND_COL`\uff08\u8fd9\u91cc\u5728SQLNet\u4e2d\u53d1\u73b0\uff0cSELECT_COL\u548cCOND_COL\u5e38\u5e38\u4f1a\u9884\u6d4b\u76f8\u540c\u7684\u5217\u540d\u3002\u6240\u4ee5\u8fd9\u91cc\u4f5c\u51fa\u4e86\u6539\u53d8\uff0c\u5728\u91cc\u9762\u516c\u5f0f\u4e2d\u65b0\u589e\u4e86\u4e00\u4e2a\u5173\u4e8eSELECT_COL\u5217\u540d\u7684\u9879.\uff09\uff1a\n\n![image.png](img/1584456364854-ed3d9289-edd0-448a-a19f-32c7a5b91de5.png)\n\n  i.  MODEL_AGG\u6a21\u5757\n\n\u8fd9\u90e8\u5206\u4e0eSQLNet\u4e00\u6837\uff0c\u90fd\u662f\u9884\u6d4b{NULL,MAX,MIN,COUNT,SUM,AVG}\u4e2d\u7684\u4e00\u79cd\u3002\n\n![image.png](img/1584456447315-7c530eb3-78cf-4c90-92c8-7e798ea0bd28.png)\n\n  i.  MODEL_OPVAL\u6a21\u5757\n\n\u9700\u8981\u9884\u6d4b\u4e24\u90e8\u5206\uff1a$OP\uff1b$COND_VAL\u3002\n\nOP\uff1a\u9884\u6d4b{=,>,<}\u4e2d\u7684\u4e00\u79cd\u3002\n\n![image.png](img/1584456573465-67624b50-08d5-438a-bdc9-f639b55a2b06.png)\n\nCOND_VAL\uff08\u501f\u9274\u4e86Pointernetwork\u7684\u601d\u60f3\u6765\u4ece\u8f93\u5165\u7684Question\u4e2d\u8003\u8651Value\u91cc\u7684\u503c\u3002\uff09\uff1a\n\n![image.png](img/1584456633425-dda329bb-494c-46bc-a5a5-5036eb880112.png)\n\n\u5176\u4e2dh\u662f\u524d\u4e00\u4e2a\u751f\u6210\u7684\u5355\u8bcd\u7684\u9690\u72b6\u6001\u3002\n\n## 5. \u6570\u636e\u96c6\nwikiSQL\n## 6. \u5b9e\u9a8c\u7ed3\u679c\nTypeSQL\u8fbe\u5230\u4e8682.6%\u7684\u6b63\u786e\u7387\n\n## 7. \u672a\u6765\u5de5\u4f5c\n\u5c06\u6765\uff0c\u6211\u4eec\u8ba1\u5212\u901a\u8fc7\u5728\u6570\u636e\u5e93\u62c6\u5206\u8bbe\u7f6e\u4e0b\u63a2\u7d22\u5176\u4ed6\u66f4\u590d\u6742\u7684\u6570\u636e\u96c6\u6765\u63a8\u8fdb\u8fd9\u9879\u5de5\u4f5c\u3002 \u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u6211\u4eec\u53ef\u4ee5\u5728\u66f4\u73b0\u5b9e\u7684\u6587\u672c\u5230SQL\u4efb\u52a1\uff08\u5305\u62ec\u8bb8\u591a\u590d\u6742\u7684SQL\u548c\u4e0d\u540c\u7684\u6570\u636e\u5e93\uff09\u4e0a\u7814\u7a76\u901a\u7528\u6a21\u578b\u7684\u6027\u80fd\u3002\n\n## 8. \u539f\u6587\u53ca\u6e90\u7801\n[\u539f\u6587](https://arxiv.org/abs/1804.09769)\n\n[\u6e90\u7801](https://github.com/taoyds/typesql)\n\n\n\n# A Comprehensive Exploration on WikiSQL with Table-Aware Word Contextualization\n\n## 1. \u4f5c\u8005\u7b80\u4ecb\n> Wonseok Hwang Jinyeong Yim Seunghyun Park Minjoon Seo\n> Clova AI, NAVER Corp.\n\n## 2. \u6587\u732e\u7c7b\u578b\nKR2ML Workshop at NeurIPS 2019 \n## 3. \u4e3b\u8981\u8d21\u732e\n\n\n\n## 4. \u65b9\u6cd5\u6982\u8ff0\n\n\n## 5. \u5b9e\u9a8c\n\n\n## 6. \u539f\u6587\u53ca\u6e90\u7801\n[\u539f\u6587](https://arxiv.org/abs/1902.01069)\n\n[\u6e90\u7801](https://github.com/naver/sqlova)\n\n\n\n\n\n# \u4e2d\u6587NL2SQL\u6311\u6218\u8d5b\n\n- \u9996\u5c4a\u4e2d\u6587NL2SQL\u6311\u6218\u8d5b\u7b2c3\u540d\u65b9\u6848+\u4ee3\u7801 by beader GitHub\uff1a\n\n  https://github.com/beader/tianchi_nl2sql\n\n- \u5929\u6c60NL2SQL\u6311\u6218\u8d5b\u51a0\u519b\u65b9\u6848 by NUDT NLP GitHub\uff1a\n\n  https://github.com/nudtnlp/tianchi-nl2sql-top1\n\n\n\n# \u3010\u667a\u80fd\u95ee\u7b54\u3011\u4ece\u5165\u95e8\u5230\u653e\u5f03\u2014\u2014DBQA\u4e0e\u673a\u5668\u9605\u8bfb\u7406\u89e3\n\n## DBQA\u4e0eMRC\u5165\u95e8\n\n- - Abstract\n\n  - Task of MRC\n\n  - History of MRC\n\n  - Dataset of MRC\n\n  - - SQuAD\n    - DuReader\n    - DuReader_robust\n    - CMRC 2018\n    - DRCD\n\n  - Models of MRC\n\n  - - Stanford Attentive Reader\n    - BiDAF\n    - Others\n\n  - Metric of MRC\n\n  - Product in Clould\n\n  - Conclusion\n\n  - Reference\n\n> DBQA\u662fdocument-based Question and Answer \u7684\u7b80\u79f0\uff0cMRC\u662fMachine Reading Comprehension\u673a\u5668\u9605\u8bfb\u7406\u89e3\u7684\u7b80\u79f0\u3002\n> \u6309\u7167\u4e2a\u4eba\u6d45\u8584\u7684\u7406\u89e3\uff0c**DBQA\u66f4\u52a0\u504f\u5411\u4e8e\u7cfb\u7edf**\uff0c\u4e1a\u52a1\u573a\u666f\u4f1a\u6bd4\u76ee\u524d\u7684\u9605\u8bfb\u7406\u89e3\u66f4\u590d\u6742\uff0c**MRC\u5219\u6bd4\u8f83\u504f\u4e8e\u4efb\u52a1\u672c\u8eab**\uff0c\u7528\u4e8e\u6307\u5b9a\u5185\u5bb9\uff08\u6587\u6863\uff09\u4e2d\u627e\u7b54\u6848\uff08\u53ef\u4ee5\u62d2\u8bc6\uff09\u3002\u5982\u679c\u7b80\u5355\u7684\u4ece\u6587\u6863\u4e2d\u62bd\u53d6\u51fa\u90e8\u5206\u5185\u5bb9\u4f5c\u4e3a\u56de\u7b54\u8fd9\u4e2a\u4efb\u52a1\u89d2\u5ea6\u4e0a\uff0c\u53ef\u4ee5\u7b80\u5355\u7684\u628a\u4e24\u8005\u7b49\u4ef7\u5316\uff0c\u6216\u8005\u6362\u53e5\u8bdd\u8bf4\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u9605\u8bfb\u7406\u89e3\u7684\u601d\u8def\u53bb\u5b9e\u73b0DBQA\u3002\u56e0\u6b64\uff0c\u867d\u7136\u672c\u6587\u4e3b\u8981\u6574\u7406\u7684\u662fMRC\u4e5f\u5f52\u7c7b\u5728\u95ee\u7b54\u4e2d\u4e86\uff08\u5927\u90e8\u5206\u53c2\u8003\u65af\u5766\u798f\u8bfe\u7a0bcs224n\uff09\n> PS\uff1a\u4fa7\u91cd\u4e8e\u4e2d\u6587MRC\uff0c\u6d89\u53ca\u8bba\u6587\u8f83\u5c11\uff08\u5f85\u540e\u7eed\u8865\u5145\uff09\n\n### Abstract\n\n\u673a\u5668\u9605\u8bfb\u7406\u89e3\u57fa\u7840\u4efb\u52a1\u662f\u6839\u636e\u95ee\u9898\uff08`Question`\uff09\uff0c\u5728\u975e\u7ed3\u6784\u5316\u6587\u6863\uff08`Passege`\uff09\u5bfb\u627e\u5408\u9002\u7684\u7b54\u6848\uff08`Answer`\uff09.\n\n`MCTestReading`\n\n![img](img/1.webp)\n\n\u901a\u5e38\u6765\u8bb2\uff0c\u57fa\u4e8e\u6587\u6863\u7684\u641c\u7d22\uff08\u53ef\u4ee5\u662fQA\uff09\u53ef\u4ee5\u5206\u4e3a2\u4e2a\u90e8\u5206\u3002\n\n1. \u4eceQuery\u4e2d\u8bc6\u522b\u7279\u5f81\uff0c\u53ec\u56de\u76f8\u5173\u6587\u6863\u3002\u8fd9\u4e2a\u8fc7\u7a0b\u4e00\u822c\u6210\u4e3a\uff08information retrieval\uff09\uff0c\u53ef\u4ee5\u901a\u8fc7\u4f20\u7edf\u7684\u4fe1\u606f\u68c0\u7d22/web\u641c\u7d22\u5904\u7406\uff08tf-idf\uff0cBM25\uff0cetc...\uff09\n2. \u4ece\u6587\u6863\u4e2d\u68c0\u7d22\u51fa\u6211\u4eec\u60f3\u8981\u7684\u7b54\u6848\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u5373MRC\u3002\n\n### Task of MRC\n\n\u603b\u7684\u6765\u770bMRC\u4efb\u52a1\u5927\u81f4\u53ef\u4ee5\u5206\u4e3a\u56db\u79cd\u7c7b\u578b\n\n- **\u5b8c\u5f62\u586b\u7a7a**\n  \u8be5\u4efb\u52a1\u76f8\u5bf9\u6bd4\u8f83\u65e9\uff0c\u6bd4\u8f83\u6709\u4ee3\u8868\u6027\u7684\u6709The Children\u2019s Book Test\uff0cCMRC2017\u7b49\u3002\n- **\u591a\u9879\u9009\u62e9/\u591a\u9879\u9009\u62e9\u5f0f**\n  \u6570\u636e\u96c6\u4e3a\uff08\u6587\u6863\uff0c\u95ee\u9898\uff0c\u5019\u9009\u7b54\u6848\u96c6\uff0c\ufffd"
    },
    {
        "entity": "Minjoon Seo",
        "step": 26983,
        "passage": " two for backward) of Skim-LSTM+Attention model. We see that the second layer skims more, implying that the second layer is more confident about which tokens are important.\nFigure 6 shows F1 score of LSTM+Attention model using standard LSTM and Skim LSTM, sorted in ascending order by Flop-R. While models tend to perform better with larger computational cost, Skim LSTM (Red) outperforms standard LSTM (Blue) with comparable computational cost. We also observe that the F1 score of Skim-LSTM is more stable across different configurations and computational cost. Moreover, increasing the value of \u03b3 for Skim-LSTM gradually increases skipping rate and Flop-R, while it also leads to reduced accuracy.\nControlling skim rate. An important advantage of Skim-RNN is that the skim rate (and thus computational cost) can be dynamically controlled at inference time by adjusting the threshold for \u2018skim\u2019 decision probability p1t (Equation 1). Figure 6 shows the trade-off between the accuracy and computational cost for two settings, confirming the importance of skimming (d\u2032>0) compared to skipping (d\u2032=0).\nVisualization. Figure 7 shows an example from SQuAD and visualizes which words Skim-LSTM (d=100,d\u2032=20) reads (red) and skims (white). As expected, the model does not skim when the input seems to be relevant to answering the question. In addition, LSTM in second layer skims more than that in the first layer mainly because the second layer is more confident about the importance of each token, as shown in Figure 7. More visualizations are shown in in Appendix C.\nd=100 (batch size = 1) in all three frameworks on a single thread of CPU (averaged over 100 trials), and have observed that NumPy is 1.5 and 2.8 times faster than TensorFlow and PyTorch.888NumPy\u2019s speed becomes similar to that of TensorFlow and PyTorch at d=220 and d=700, respectively. At larger hidden size, NumPy becomes slower. This seems to be mostly due to the fact that the frameworks are primarily (optimized) for GPUs and they have larger overhead than NumPy that they cannot take much advantage of reducing the size of the hidden state of the LSTM below 100.\nFigure 8: Speed up rate of Skim-LSTM (vs LSTM) with varying skimming rates and hidden state sizes.\nFigure 8 shows the relative speed gain of Skim-LSTM compared to standard LSTM with varying hidden state size and skim rate. We use NumPy, and the inferences are run on a single thread of CPU. We also plot the ratio between the reduction of the number of float operations (Flop-R) of LSTM and Skim-LSTM. This can be considered as a theoretical upper bound of the speed gain on CPUs. We note two important observations. First, there is an inevitable gap between the actual gain (solid line) and the theoretical gain (dotted line). This gap will be larger with more overhead of the framework, or more parallelization (e.g. multithreading). Second, the gap decreases as the hidden state size increases because the the overhead becomes negligible with very large matrix operations. Hence, the benefit of Skim-RNN will be greater for larger hidden state size.\nLatency. A modern GPU has much higher throughput than a CPU with parallel processing. However, for small networks, the CPU often has lower latency than the GPU. Comparing between NumPy with CPU and TensorFlow with GPU (Titan X), we observe that the former has 1.5 times lower latency (75 \\upmus vs 110 \\upmus per token) for LSTM of d=100. This means that combining Skim-RNN with CPU-based framework can lead to substantially lower latency than GPUs. For instance, Skim-RNN with CPU on IMDb has 4.5x lower latency than a GPU, requiring only 29 \\upmus per token on average.\nWe present Skim-RNN, a recurrent neural network that can dynamically decide to use the big RNN (read) or the small RNN (skim) at each time step, depending on the importance of the input. While Skim-RNN has significantly lower computational cost than its RNN counterpart, the accuracy of Skim-RNN is still on par with or better than standard RNNs, LSTM-Jump, and VCRNN. Since Skim-RNN has the same input and output interface as an RNN, it can easily replace RNNs in existing applications. We also show that a Skim-RNN can offer better latency results on a CPU compared to a standard RNN on a GPU. Future work involves using Skim-RNN for applications that require much higher hidden state size, such as video understanding, and using multiple small RNN cells for varying degrees of skimming.\nThis research was supported by the NSF (IIS 1616112), Allen Distinguished Investigator Award, Samsung GRO award, and gifts from Google, Amazon, Allen Institute for AI, and Bloomberg. We thank the anonymous reviewers for their helpful comments.\nBalduzzi & Ghifary (2016) David Balduzzi and Muhammad Ghifary. Strongly-typed recurrent neural networks. In ICML, 2016.\nCampos et al. (2017) V\u00edctor Campos, Brendan Jou, Xavier Gir\u00f3-i Nieto, Jordi Torres, and Shih-Fu Chang. Skip rnn: Learning to skip state updates in recurrent neural networks. arXiv preprint arXiv:1708.06834, 2017.\nChoi et al. (2017) Eunsol Choi, Daniel Hewlett, Alexandre Lacoste, Illia Polosukhin, Jakob Uszkoreit, and Jonathan Berant. Coarse-to-fine question answering for long documents. In ACL, 2017.\nChung et al. (2017) Junyoung Chung, Sungjin Ahn, and Yoshua Bengio. Hierarchical multiscale recurrent neural networks. In ICLR, 2017.\nDyer et al. (2016) Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A Smith. Recurrent neural network grammars. In NAACL, 2016.\nHahn & Keller (2016) Michael Hahn and Frank Keller. Modeling human reading with neural attention. In EMNLP, 2016.\nJang et al. (2017) Eric Jang, Shixiang Gu, and Ben Poole. Categorical reparameterization with gumbel-softmax. In ICLR, 2017.\nJernite et al. (2017) Yacine Jernite, Edouard Grave, Armand Joulin, and Tomas Mikolov. Variable computation in recurrent neural networks. In ICLR, 2017.\nJohansen et al. (2017) Alexander Johansen, Bryan McCann, James Bradbury, and Richard Socher. Learning when to read and when to skim, 2017. URL https://metamind.io/research/learning-when-to-skim-and-when-to-read.\nJoshi et al. (2017) Mandar Joshi, Eunsol Choi, Daniel S. Weld, and Luke Zettlemoyer. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In ACL, 2017.\nKembhavi et al. (2017) Aniruddha Kembhavi, Minjoon Seo, Dustin Schwenk, Jonghyun Choi, Ali Farhadi, and Hannaneh Hajishirzi. Are you smarter than a sixth grader? textbook question answering for multimodal machine comprehension. In CVPR, 2017.\nKokkinos & Potamianos (2017) Filippos Kokkinos and Alexandros Potamianos. Structural attention neural networks for improved sentiment analysis. arXiv preprint arXiv:1701.01811, 2017.\nKong et al. (2016) Lingpeng Kong, Chris Dyer, and Noah A Smith. Segmental recurrent neural networks. In ICLR, 2016.\nMarcel Adam Just (1987) Patricia Anderson Carpenter Marcel Adam Just. The Psychology of Reading and Language Comprehension. 1987.\nMikolov et al. (2015) Tomas Mikolov, Armand Joulin, Sumit Chopra, Michael Mathieu, and Marc\u2019Aurelio Ranzato. Learning longer memory in recurrent neural networks. In ICLR Workshop, 2015.\nMin et al. (2017) Sewon Min, Minjoon Seo, and Hannaneh Hajishirzi.\nQuestion answering through transfer learning from large fine-grained supervision data.\nMiyato et al. (2017) Takeru Miyato, Andrew M. Dai, and Ian Goodfellow. Adversarial training methods for semi-supervised text classification. In ICLR, 2017.\nMnih et al. (2014) Volodymyr Mnih, Nicolas Heess, Alex Graves, et al. Recurrent models of visual attention. In NIPS, 2014.\nOdena et al. (2017) Augustus Odena, Dieterich Lawson, and Christopher Olah.\nChanging model behavior at test-time using reinforcement learning.\nIn ICLR Workshop, 2017.\nRastegari et al. (2016) Mohammad Rastegari, Vicente Ordonez, Joseph Redmon"
    },
    {
        "entity": "Minjoon Seo",
        "step": 27048,
        "passage": ", it was very cold, and we were out of practice at being cold. We never really had a winter in 2021, as we moved to Tenerife before the coldest parts of winter in San Diego came. It was only a 15 minute walk from the train station to the Airbnb, but we were freezing by the time we arrived. The Airbnb was a nice enough place, but with a little bit of an odd layout and it was pretty sparsely furnished. For example, there was no shampoo or conditioner, and we hadn\u2019t brought any, so we made a note to just pick some up at the store.\nAfter we got changed into some warmer clothes, we went out to explore the city. All we knew about Trier was that it had a charming Old Town with a nice Christmas Market, and some ancient Roman ruins in a couple spots around town. Interestingly, there were lots of pride flags in abundance as we walked towards the Old Town. As we passed by the Dom (Saint Peter\u2019s Cathedral), we saw an open Christmas Market, and gave each other a high five. No matter what else might transpire on the rest of the trip, we\u2019d at least get to enjoy one Christmas Market in Europe.\nAll that being said, the first market was very small, and frankly kind of sad. There was security checking for vaccinations in order to enter the market, and the market was fenced around the perimeter. But once inside, there were only a dozen or so chalets, and maybe because it was mid-day, almost no patrons. None of the food or drink jumped out at us, so we decided to see what else was around. Just a block or so away there was a larger market, albeit still a small one compared to what we were used to from Vienna, Prague, Budapest, etc. But we did get some sausages and fries, and tried to scarf them down before the cold air turned the food cold. It was right around 0 celsius (32 Fahrenheit), and every time we had to take our gloves off, our hands got very cold, very fast.\nAfter leaving the second market, we walked around the city center, and north up to Porta Nigra. The Porta Nigra is a really old, really big gate from when the Romans were in the area. According to Wikipedia, the Porta Nigra is the largest Roman city gate north of the Alps. It was constructed in the second century, around 170 AD. It was one of four city gates built in Trier, the one on the north side, and is the only one of the four still in existence. Seeing it today, it was quite impressive, but at the same time it was odd just seeing it freestanding around other, newer buildings.\nOutdoor lights started to come on at 15:00. We knew it was going to get dark early, but this was even earlier than expected. Sunset was supposed to be right around 16:00. Justin was having issues with his gloves, using them with the cameras, etc. - again, he was out of practice. Neither one of us was wearing our long underwear, and we quickly regretted that. The Old Town was quite small, and it didn\u2019t take very long for us to walk from one side to the other. At some of the travel agencies around town, we saw trips to Puerto de la Cruz advertised, which was a bit surprising. Yes, there were numerous German tourists and expats in Puerto, but we didn\u2019t consider where in Germany they might be coming from. Crystal also saw a potato-themed restaurant with a sizable menu (Kartoffel Kiste), which we kept in mind for later.\nWe went back to the Airbnb to put on proper clothes, as it was going to get only colder with the sun down. Crystal had a Hungarian class at 17:00, and was having a hard time staying awake until then. Whilst she took her class, Justin checked out restaurants, things to do, the possibility of going to Luxembourg for a day trip (which we could now do if we wanted, go figure), etc. He found a restaurant that looked interesting (Wirsthaus Zur Glocke), and we decided to go there for dinner. He also decided to cut the right index-finger fingertip from his gloves, so that he could keep the gloves on but still be able to feel the buttons on the camera with at least one finger. Sure, that finger would be freezing, but better one fingertip than a whole hand.\nWith our proper clothing, and with Justin\u2019s glove missing a finger, we went out again. We were quite a bit warmer, but still cold. Wirsthaus Zur Glocke was full for dinner tonight, but Crystal was able to make us a reservation for tomorrow. So now without any semblance of a plan, we just meandered around the Old Town, seeing if anything caught our attention. There was a very light mist. The city center looked better with all the lights on, and the markets looked charming, even if we weren\u2019t fans of what they were selling.\nAfter it was all said and done, we ended up deciding to eat at Kartoffel Kiste. The host told Justin he needed a better mask, which Crystal thankfully had in her purse. Justin put that on, we walked to our seat, and then once seated we took our masks off completely. Whatever. Crystal ordered a sparkling wine, and Justin got a 0.5L Hefeweizen. Crystal ordered a roast pork dish (Trierer Spiessbraten), and Justin ordered a meatball wrapped in potato and covered in cheese (Trierer Gef\u00fcllte). About halfway through, we ordered a second round, red wine for Crystal, and another Hef for Justin. After we were done eating, Crystal ordered us some potato schnapps, which tasted like Vodka - go figure. When we left the restaurant, Crystal thought she lost her hat. Once back at the house, however, she realized she had not lost her hat, but it was camouflaged at the bottom of her purse. Somehow we\u2019d made it to 22:00, and we were pretty happy with that, hoping it would help with jet lag. We crashed almost immediately once back in the Airbnb.<|endoftext|>ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators, Kevin Clark, et al., ICLR, 2020.\nTinyBERT: Distilling BERT for Natural Language Understanding, Xiaoqi Jiao, et al., ICLR, 2020.\nMINILM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers, Wenhui Wang, et al., arXiv, 2020.\nT5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer, Colin Raffel, et al., arXiv preprint, 2019.\nERNIE: Enhanced Language Representation with Informative Entities, Zhengyan Zhang, et al., ACL, 2019.\nXLNet: Generalized Autoregressive Pretraining for Language Understanding, Zhilin Yang, et al., arXiv preprint, 2019.\nALBERT: A Lite BERT for Self-supervised Learning of Language Representations, Zhenzhong Lan, et al., arXiv preprint, 2019.\nRoBERTa: A Robustly Optimized BERT Pretraining Approach, Yinhan Liu, et al., arXiv preprint, 2019.\nDistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter, Victor sanh, et al., arXiv, 2019.\nSpanBERT: Improving Pre-training by Representing and Predicting Spans, Mandar Joshi, et al., TACL, 2019.\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, Jacob Devlin, et al., NAACL 2019, 2018.\nTANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection, Siddhant Garg, et al., AAAI 2020, Nov 2019.\nOverview of the MEDIQA 2019 Shared Task on Textual Inference, Question Entailment and Question Answering, Asma Ben Abacha, et al., ACL-W 2019, Aug 2019.\nTowards Scalable and Reliable Capsule Networks for Challenging NLP Applications, Wei Zhao, et al., ACL 2019, Jun 2019.\nCognitive Graph for Multi-Hop Reading Comprehension at Scale, Ming Ding, et al., ACL 2019, Jun 2019.\nReal-Time Open-Domain Question Answering with Dense-Sparse Phrase Index, Minjoon Seo, et al., ACL 2019, Jun 2019.\nUnsupervised Question Answering by Cloze Translation, Patrick Lewis, et al., ACL 2019, Jun 2019.\nSemEval-2019 Task 10: Math Question Answering, Mark Hopkins, et al., ACL-W 2019, Jun 2019.\nImproving Question Answering over Incomplete KBs with Knowledge-Aware Reader, Wenhan Xiong, et al., ACL 2019, May 2019.\nMatching Article Pairs with Graphical Decomposition and Convolutions, Bang Liu, et al., ACL 2019, May 2019.\nEpisodic Memory Reader: Learning what to Remember for Question Answering from Streaming Data, Moonsu Han, et al., ACL 2019, Mar 2019.\nNatural Questions: a Benchmark for Question Answering Research, Tom Kwiatkowski, et al., TACL 2019, Jan 2019.\nTextbook Question"
    }
]